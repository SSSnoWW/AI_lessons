{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Продвинутый блок | Обнаружение объектов (Object Detection). Модель YOLOv3 (практика 3) | УИИ",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSSnoWW/AI_lessons/blob/lessons/%D0%9F%D1%80%D0%BE%D0%B4%D0%B2%D0%B8%D0%BD%D1%83%D1%82%D1%8B%D0%B9_%D0%B1%D0%BB%D0%BE%D0%BA_%7C_%D0%9E%D0%B1%D0%BD%D0%B0%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2_(Object_Detection)_%D0%9C%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C_YOLOv3_(%D0%BF%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0_3)_%7C_%D0%A3%D0%98%D0%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZKnHkcHse-D"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/15jlTRqgJCqFbyw_bSg9UTB1cBjH5SYt_?usp=sharing)\n",
        "2. [Практический ноутбук 1](https://colab.research.google.com/drive/1qNMeH5RPNG3kJQrH5FbyfsJUCzA3xPRO?usp=sharing)\n",
        "3. [Практический ноутбук 2](https://colab.research.google.com/drive/1638S62UBT1_uaBXcE7qT1AoagPRB_zJP?usp=sharing)\n",
        "4. Практический ноутбук 3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hIW4GducxL01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции из ранее пройденных материалов (теория и практика 1):"
      ],
      "metadata": {
        "id": "wAO8Y1uiUHso"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nQ-goM2FzgG"
      },
      "source": [
        "# для измерения времени обучения\n",
        "import time\n",
        "\n",
        "# для создания случайных величин\n",
        "import random\n",
        "\n",
        "# Импортируем tensorflow\n",
        "import tensorflow as tf \n",
        "\n",
        "# бэкенд Keras\n",
        "import tensorflow.keras.backend as K \n",
        "\n",
        "# функции для детализации и управления процессом обучения\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# функция для отрисовки структуры модели\n",
        "from keras.utils.vis_utils import plot_model \n",
        "\n",
        "# Модули конвертации между RGB и HSV\n",
        "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb \n",
        "\n",
        "# Модули работы с изображениями\n",
        "from PIL import Image, ImageDraw, ImageFont \n",
        "\n",
        "import struct\n",
        "import gdown\n",
        "\n",
        "# библиотека numpy\n",
        "import numpy as np\n",
        "\n",
        "# Слои нейронной сети\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D, Lambda\n",
        "\n",
        "# Оптимизатор Adam\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "# работа со слоями\n",
        "from keras.layers.merge import add, concatenate\n",
        "\n",
        "# создание моделей\n",
        "from keras.models import Model\n",
        "\n",
        "# загрузчик сохраненных моделей\n",
        "from keras.models import load_model\n",
        "\n",
        "# итератор, повторно возвращающий указанный объект \n",
        "from itertools import repeat\n",
        "\n",
        "# регуляризатор, который применяет штраф за регуляризацию L2\n",
        "from tensorflow.keras.regularizers import l2 \n",
        "\n",
        "# модуль для отрисовки изображения\n",
        "from tensorflow.keras.preprocessing import image \n",
        "\n",
        "# Функция для отрисовки структуры модели\n",
        "from keras.utils.vis_utils import plot_model \n",
        "\n",
        "# Импортируем tensorflow\n",
        "import tensorflow as tf \n",
        "\n",
        "# gрямоугольник, определяемый точкой привязки xy , а также его шириной и высотой\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# возвращение списка (возможно, пустого) путей, соответствующих шаблону pathname\n",
        "from glob import glob\n",
        "\n",
        "# библиотека для работы с файлами\n",
        "import os\n",
        "\n",
        "# визуализация \n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "weights_path = gdown.download('https://storage.googleapis.com/datasets_ai/Advanced/9_OD/yolo_new.h5', None, quiet=True)\n",
        "\n",
        "size = 416 # Размер входного изображения для модели YOLO\n",
        "\n",
        "import numpy as np\n",
        "anchors = np.array([[10,13], [16,30], [33,23], [30, 61], [62,45], [59,119], [116, 90], [156, 198], [373, 326]])\n",
        "num_anchors = anchors.shape[0]\n",
        "\n",
        "inputs = Input(shape = (size, size, 3)) \n",
        "channels= 3\n",
        "num_sub_anchors = 3\n",
        "\n",
        "name_classes = ['Самолеты']\n",
        "num_classes = len(name_classes) # чило классов в новом датасете"
      ],
      "metadata": {
        "id": "H5S2R6HrmKC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DBL(x, filters, kernel, strides=1, batch_norm=True, layer_idx=None): # DarknetConv2D_BN_Leaky\n",
        "   \n",
        "    '''\n",
        "    Функция реализует блок DBL в составе моделей Darknet и YOLO\n",
        "    \n",
        "    Args:\n",
        "        x - тензор входных данных\n",
        "        filter - количество фильтров на слой, целое число\n",
        "        kernel - размер ядра свертки, целое число\n",
        "        stride - шаг свертки, целое число\n",
        "        batch_norm - включать или ветку со слоем Batchnormalization и активационной функцией LeakyReLu. \n",
        "        layer_idx - номер слоя\n",
        "    \n",
        "    Return:\n",
        "        x - тензор выходных данных\n",
        "        layer_idx+1 -номер следующего слоя\n",
        "        '''\n",
        "    \n",
        "    if strides == 1:\n",
        "        padding = 'same'\n",
        "    else:\n",
        "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # Делаем oтступ в виде нулей по контуру изображения, что бы захватить левый верхний угол\n",
        "        padding = 'valid'\n",
        "    \n",
        "    x = Conv2D(filters=filters, kernel_size=kernel,\n",
        "              strides=strides, padding=padding,\n",
        "              use_bias=not batch_norm, kernel_regularizer=l2(0.0005), name='conv_' + str(layer_idx))(x)\n",
        "    \n",
        "    if batch_norm:\n",
        "        x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(layer_idx))(x)\n",
        "        x = LeakyReLU(alpha=0.1,name='leake_' + str(layer_idx))(x)\n",
        "    \n",
        "    return x, layer_idx+1"
      ],
      "metadata": {
        "id": "iCTR_gT6ULRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Res_unit(x, filters, layer_idx): # DarknetResidual\n",
        "\n",
        "    '''\n",
        "    Функция определяет минимальную ячейку Residual блока\n",
        "    \n",
        "    Args:\n",
        "        x - тензор входных данных\n",
        "        filter - количество фильтров на слой, целое число\n",
        "        layer_idx - номер слоя\n",
        "    \n",
        "    Return:\n",
        "        x - тензор выходных данных\n",
        "        layer_idx+1 - номер следующего слоя\n",
        "        '''\n",
        "    skip_connection = x\n",
        "    x, layer_idx = DBL(x, filters // 2, kernel=1, layer_idx=layer_idx)\n",
        "    x, layer_idx = DBL(x, filters, kernel=3, layer_idx=layer_idx)\n",
        "    x = add([skip_connection , x], name='Add_'+str(layer_idx))\n",
        "\n",
        "    return x, layer_idx+1"
      ],
      "metadata": {
        "id": "YbHOHTikUVxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResBlock(x, filters, blocks, layer_idx): # DarknetBlock\n",
        "\n",
        "    '''\n",
        "    Функция определяет Residual блок состоящий из входного сверточного слоя \n",
        "    и последовательности Res_unit блоков\n",
        "    \n",
        "    Args:\n",
        "        x - тензор входных данных\n",
        "        filters - задает количество фильтров\n",
        "        block - задает количество Residual 'ячеек', а именно, сколько раз повторить в цикле функцию Res_unit\n",
        "        layer_idx - номер слоя\n",
        "    \n",
        "    Return:\n",
        "        x - тензор выходных данных\n",
        "        layer_idx -номер слоя\n",
        "        \n",
        "        '''\n",
        "    x, layer_idx = DBL(x, filters, kernel=3, strides=2, layer_idx=layer_idx)\n",
        "    \n",
        "    for _ in repeat(None, blocks):\n",
        "        x, layer_idx = Res_unit(x, filters, layer_idx=layer_idx)\n",
        "    \n",
        "    return x, layer_idx"
      ],
      "metadata": {
        "id": "P8ebZ5elUc8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Detector(x_in, filters, layer_idx=None):\n",
        "   \n",
        "    '''\n",
        "    Функция реализует блок DBL в составе моделей Darknet и YOLO\n",
        "    \n",
        "    Args:\n",
        "        x_in - тензор или список тензоров\n",
        "        filters - количество фильтров\n",
        "        layer_idx - номер следующего сверточного слоя\n",
        "    Return:\n",
        "        bboxes - рамки\n",
        "        fork - тензор\n",
        "        layer_idx - номер слоя\n",
        "\n",
        "    '''\n",
        "\n",
        "    if isinstance(x_in, list): # Если на вход поступает список попадаем в эту ветку (маршруты 2 и 3)\n",
        "        x, x_skip = x_in[0], x_in[1]# Разбиваем список на отдельные тензоры\n",
        "        x,layer_idx = DBL(x, filters, kernel=1, strides=1, layer_idx=layer_idx) # DarknetConv\n",
        "        x = UpSampling2D(2, name = 'UpSampling_' + str(layer_idx))(x) # Повышаем размерность тензора\n",
        "        layer_idx+=1\n",
        "        x =concatenate([x, x_skip], name = 'Concatenate_' + str(layer_idx)) # Объединяем маршруты\n",
        "        layer_idx+=1\n",
        "        \n",
        "        # Пять сверточных слоев DBL*5 \n",
        "        for i in range(2):\n",
        "          x, layer_idx = DBL(x, filters, 1, layer_idx=layer_idx)      # 1,3\n",
        "          x, layer_idx = DBL(x, filters * 2, 3, layer_idx=layer_idx)  # 2,4\n",
        "        \n",
        "        fork, layer_idx = DBL(x, filters, 1, layer_idx=layer_idx)      # 5 С пятого слоя каскада делаем вилку на выход и на другой масштаб         \n",
        "    \n",
        "    else: # В эту ветку попадает только маршрут 1\n",
        "        x = x_in\n",
        "        \n",
        "        # Пять сверточных слоев DBL*5 \n",
        "        for i in range(2):\n",
        "          x, layer_idx = DBL(x, filters, 1, layer_idx=layer_idx)      # 1,3\n",
        "          x, layer_idx = DBL(x, filters * 2, 3, layer_idx=layer_idx)  # 2,4\n",
        "        \n",
        "        fork, layer_idx = DBL(x, filters, 1, layer_idx=layer_idx)      # 5 С пятого слоя каскада делаем вилку на выход и на другой масштаб \n",
        "\n",
        "    # Предпоследний сверточный слой (№80 13х13х1024, #92 26x26x512, #104 52x52x256)\n",
        "    x,layer_idx = DBL(fork, filters=filters*2, kernel=3, strides=1, layer_idx=layer_idx)\n",
        "\n",
        "    # Выходные слои (№81 13х13х (anchors * (4 + 1 + classes)), №93 26х26, №105 52х52 (255) \n",
        "    bboxes, layer_idx = DBL(x, filters=num_sub_anchors * (4 + 1 + num_classes), kernel=1, strides=1, batch_norm= False, layer_idx=layer_idx)       \n",
        "\n",
        "    return bboxes, fork, layer_idx"
      ],
      "metadata": {
        "id": "GbBSH4r1UlR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3V6M4Ku_50f"
      },
      "source": [
        "def create_yolov3_model(inputs, num_sub_anchors, num_classes):\n",
        "    \n",
        "    '''\n",
        "    Функция реализует блок DBL в составе моделей Darknet и YOLO\n",
        "    \n",
        "    Args:\n",
        "        inputs - входной тензор  \n",
        "        num_sub_anchors - количество анкоров \n",
        "        num_classes - количество классов\n",
        "    \n",
        "    Return:\n",
        "        model - модель\n",
        "\n",
        "    '''\n",
        "    layer_idx = 0 # Номер первого слоя\n",
        "    x, layer_idx = DBL(inputs, filters=32, kernel=3, layer_idx=layer_idx)       # DarknetConv 1 слой\n",
        "    x, layer_idx = ResBlock(x, filters=64, blocks=1, layer_idx=layer_idx)            # DarknetBlock 3 слоя\n",
        "    x, layer_idx = ResBlock(x, filters=128, blocks=2, layer_idx=layer_idx)           # DarknetBlock 5 слоя\n",
        "    x, layer_idx = Route_1,_ = ResBlock(x, filters=256, blocks=8, layer_idx=layer_idx) # DarknetBlock 9 слоев\n",
        "    x, layer_idx = Route_2,_ = ResBlock(x, filters=512, blocks=8, layer_idx=layer_idx) # DarknetBlock 9 слоев\n",
        "    Route_3, layer_idx = ResBlock(x, filters=1024, blocks=4, layer_idx=layer_idx)          # последние 4 Res блока Darknet\n",
        "    \n",
        "    # 5 сверточных слоев DBL\n",
        "    bbox_scale_1, fork_1, layer_idx = Detector(Route_3, filters=512, layer_idx=layer_idx) \n",
        "\n",
        "    # 82 слой на первый выход  83 пропуск\n",
        "    layer_idx = 84\n",
        "    bbox_scale_2, fork_2, layer_idx = Detector([fork_1, Route_2], filters=256, layer_idx=layer_idx) # 6 слоев\n",
        " \n",
        "    # слои 94-95 пропущены\n",
        "    layer_idx = 96\n",
        "    bbox_scale_3, _, layer_idx = Detector([fork_2, Route_1], filters=128, layer_idx=layer_idx) # 6 слоев\n",
        "\n",
        "    model = Model (inputs, [bbox_scale_1, bbox_scale_2, bbox_scale_3])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xmL6owvv5Q_"
      },
      "source": [
        "def yolo_loss(inputs, num_anchors):\n",
        "\n",
        "    ''' Функция рассчитывает отношение пересечение над объединениеми.\n",
        "        Args:\n",
        "            box1 - координаты рамки.\n",
        "            box2 - координаты рамки.\n",
        "        Return:\n",
        "            значение ошибки IoU.\n",
        "       \n",
        "        '''\n",
        "    # Порог вероятности обнаружения объекта\n",
        "    ignore_thresh = .5 \n",
        "    \n",
        "    # Подсчитываем количество анкоров на каждом уровне сетки\n",
        "    num_layers = num_anchors // 3 \n",
        "    \n",
        "    # Из входных данных выцепляем посчитанные моделью значения\n",
        "    y_pred = inputs[:num_layers] \n",
        "    \n",
        "    # Из входных данных выцепляем эталонные значения\n",
        "    y_true = inputs[num_layers:] \n",
        "    \n",
        "    # Задаем маску анкоров для каждого уровня сеток\n",
        "    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]] \n",
        "   \n",
        "    # Получаем размерность входного изображения ( (13 х 13) * 32 = (416 х 416)) и приводим к типу элемента y_true[0]\n",
        "    input_shape = K.cast(K.shape(y_pred[0])[1:3] * 32, K.dtype(y_true[0])) \n",
        "    \n",
        "    # Получаем двумерный массив, соответствующий размерностям сеток ((13, 13), (26, 26), (52, 52))\n",
        "    grid_shapes = [K.cast(K.shape(y_pred[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
        "    \n",
        "    loss = 0 # Значение ошибки\n",
        "    \n",
        "    # Размер пакета\n",
        "    m = K.shape(y_pred[0])[0] \n",
        "\n",
        "    # Преобразуем к типу y_pred[0]\n",
        "    batch_size = K.cast(m, K.dtype(y_pred[0])) \n",
        "    \n",
        "    for l in range(num_layers): # Пробегаем по всем трем уровням сеток\n",
        "       \n",
        "        # Получаем маску для сетки l-го уровня по вероятности определения объекта (5-ый параметр в списке общих параметров). \n",
        "        # В массиве object_mask будут значения, которые соответствуют только вероятности обнаружения объекта\n",
        "        object_mask = y_true[l][..., 4:5] # Вернется набор данных вида: ([0][0][0][0]...[1]...[0])\n",
        "        \n",
        "        # Получаем аналогичную выборку для сетки l-го уровня с OHE (где записана позиция нашего класса)\n",
        "        # В массиве true_class будут значения, которые соответсвуют только OHE представлению класса ядля данного уровня анкоров\n",
        "        true_class = y_true[l][..., 5:] # Вернется набор данных вида: ([0][0][0][0]...[1]...[0])\n",
        "        \n",
        "        num_sub_anchors = len(anchors[anchor_mask[l]]) # Получаем количество анкоров для отдельного уровян сетки (3)\n",
        "        \n",
        "        # Решейпим анкоры отдельного уровня сетки и записываем в переменную anchors_tensor\n",
        "        anchors_tensor = K.reshape(K.constant(anchors[anchor_mask[l]]), [1, 1, 1, num_sub_anchors, 2])\n",
        "        \n",
        "        # Создаем двумерный массив grid со значениями [[[0, 0] , [0, 1] , [0, 2] , ... , [0, k]], \n",
        "        #                                             [[1, 0] , [1, 1] , [1, 2] , ... , [1 ,k]],\n",
        "        #                                             ...\n",
        "        #                                             [[k, 0] , [k, 1] , [k, 2] , ... , [k, k]]]\n",
        "        # где k - размерность сетки. Массив хранит индексы ячеек сетки\n",
        "        grid_shape = K.shape(y_pred[l])[1:3] # Получаем ширину и высоту сетки\n",
        "        grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),[1, grid_shape[1], 1, 1]) # Создаем вертикальную линию\n",
        "        grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),[grid_shape[0], 1, 1, 1]) # Создаем горизонтальную линию\n",
        "        grid = K.concatenate([grid_x, grid_y]) # Объединяем \n",
        "        grid = K.cast(grid, K.dtype(y_pred[l])) # Приводим к типу y_pred[l]\n",
        "        \n",
        "        # Решейпим y_pred[l]                 13                13              3              6\n",
        "        feats = K.reshape(y_pred[l], [-1, grid_shape[0], grid_shape[1], num_sub_anchors, num_classes + 5]) \n",
        "        \n",
        "        # -- Считаем ошибку в определении координат центра объекта\n",
        "\n",
        "        # Получаем координаты центра объекта из спредиктенного значения\n",
        "        pred_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats)) # три точки ... означают, что мы берем все параметры до запятой ,\n",
        "        # Производим обратные вычесления для оригинальных значений из y_true для координат центра объекта\n",
        "        true_xy = y_true[l][..., :2] * grid_shapes[l][::-1] - grid  # Реальные координаты центра bounding_box\n",
        "        box_loss_scale = 2 - y_true[l][...,2:3] * y_true[l][...,3:4] # чем больше бокс, тем меньше ошибка\n",
        "        # binary_crossentropy для истинного значения и спредиктенного (obect_mask для подсчета только требуемого значения)\n",
        "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(true_xy, feats[...,0:2], from_logits=True)\n",
        "\n",
        "        # --- Считаем ошибку в определении координат ширины и высоты\n",
        "\n",
        "        # Получаем значения ширины и высоты изображения из спредиктенного значения   \n",
        "        pred_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats)) \n",
        "        # Производим обратные вычесления для оригинальных значений из y_true для ширины и высоты объекта\n",
        "        true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1]) \n",
        "        # Оставляем значение высоты и ширины только у тех элементов, где object_mask = 1\n",
        "        true_wh = K.switch(object_mask, true_wh, K.zeros_like(true_wh)) \n",
        "        # Считаем значение ошибки в определении высоты и ширины\n",
        "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(true_wh-feats[...,2:4])\n",
        "        \n",
        "        # Объединяем значения в один  массив\n",
        "        pred_box = K.concatenate([pred_xy, pred_wh]) \n",
        "        \n",
        "        # Считаем ошибку в определении обнаружения какого-либо класса\n",
        "        # Для этого вначале надо отсечь все найденные объекты, вероятность которых меньше установленного значения ignore_thresh\n",
        "        \n",
        "        # Определяем массив, который будет хранить данные о неподходящих значениях\n",
        "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True) \n",
        "        object_mask_bool = K.cast(object_mask, 'bool') # Приводим тип object_mask к типу 'bool'\n",
        "        \n",
        "        # Функция, определяющая данные, которые требуется игнорировать\n",
        "        # Пробегаем по всем элементам пакета (b<m)\n",
        "        # Получаем параметры реального bounding_box для текущей ячейки\n",
        "        # Считаем IoU реального и спредиктенного\n",
        "        # В зависимости от best_iou < ignore_thresh помечаем его как верно распознанный или неверено\n",
        "        \n",
        "        def loop_body(b, ignore_mask):\n",
        "\n",
        "            ''' \n",
        "            Функция рассчитывает отношение пересечение над объединениеми.\n",
        "            Args:\n",
        "                b - элемент пакета\n",
        "                ignore_mask - координаты рамки.\n",
        "            Return:\n",
        "                b+1 - следующий элемент пакета\n",
        "                ignore_mask - координаты рамки.\n",
        "             '''\n",
        "            \n",
        "            # в true_box запишутся первыые 4 параметра (центр, высота и ширина объекта) того элемента, значение которого в object_mask_bool равно True\n",
        "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0]) \n",
        "            \n",
        "            # Подсчитываем iou для спредиктенной ограничивающей рамки (pred_box) и оригинальной (true_box)\n",
        "            iou = calc_iou(pred_box[b], true_box) \n",
        "            \n",
        "            # Находим лучшую ограничивающую рамку\n",
        "            best_iou = K.max(iou, axis=-1) \n",
        "            \n",
        "            # Записываем в ignore_mask true или false в зависимости от (best_iou < ignore_thresh)\n",
        "            ignore_mask = ignore_mask.write(b, K.cast(best_iou < ignore_thresh, K.dtype(true_box))) \n",
        "            \n",
        "            return b+1, ignore_mask  \n",
        "        \n",
        "        # Пробегаем в цикле по всем элементам в пределах значения m (m = batch size)\n",
        "        _, ignore_mask = tf.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask]) \n",
        "        ignore_mask = ignore_mask.stack() # Приводим ignore_mask к тензору\n",
        "        ignore_mask = K.expand_dims(ignore_mask, -1) # Добавляем еще одну размерность в конце ignore_mask\n",
        "                 \n",
        "        # Считаем значение ошибки\n",
        "        # 1 компонента - для значений, которые были верно спредиктены\n",
        "        # 2 компонентя - для значения, которые были неверно спредиктены\n",
        "        confidence_loss = (\n",
        "            object_mask * K.binary_crossentropy(object_mask, feats[...,4:5], from_logits=True) +\n",
        "            (1-object_mask) * K.binary_crossentropy(object_mask, feats[...,4:5], from_logits=True) * ignore_mask\n",
        "            )\n",
        "        \n",
        "        # Считаем ошибку в определении класса объекта\n",
        "        class_loss = object_mask * K.binary_crossentropy(true_class, feats[...,5:], from_logits=True)\n",
        "    \n",
        "        # Считаем суммарную ошибку\n",
        "        xy_loss = K.sum(xy_loss) / batch_size\n",
        "        wh_loss = K.sum(wh_loss) / batch_size\n",
        "        confidence_loss = K.sum(confidence_loss) / batch_size\n",
        "        class_loss = K.sum(class_loss) / batch_size\n",
        "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
        "                \n",
        "    return loss # Возвращаем значение ошибки   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_iou(input1, input2):\n",
        "    \n",
        "    ''' Функция подсчета коэффициента пересечения IoU\n",
        "        Args: \n",
        "            input1 - \n",
        "            input2 -\n",
        "        Return:\n",
        "            ошибка IoU \n",
        "\n",
        "        '''\n",
        "\n",
        "    # Добавляем одну размерность\n",
        "    input1 = K.expand_dims(input1, -2) \n",
        "    input2 = K.expand_dims(input2, 0)\n",
        "    \n",
        "    # Получаем координаты x,y центра \n",
        "    xy1 = input1[..., :2] \n",
        "    xy2 = input2[..., :2]\n",
        "\n",
        "    # Получаем значения высоты и ширины\n",
        "    wh1 = input1[..., 2:4] \n",
        "    wh2 = input2[..., 2:4] \n",
        "    \n",
        "    # Делим значения высоты и ширины пополам\n",
        "    wh_half1 = wh1 / 2. \n",
        "    wh_half2 = wh2 / 2.\n",
        "    \n",
        "    # Получаем значение, соответствующее верхнему левому углу\n",
        "    top_left1 = xy1 - wh_half1 \n",
        "    top_left2 = xy2 - wh_half2\n",
        "    \n",
        "    # Получаем значение, соотвествующее правому нижнему углу\n",
        "    right_bottom1 = xy1 + wh_half1 \n",
        "    right_bottom2 = xy2 + wh_half2\n",
        "\n",
        "    # Берем максимальные координаты из левых верхних углов\n",
        "    intersect_mins = K.maximum(top_left1, top_left2) \n",
        "\n",
        "    # Берем Минимальные координаты координаты из правых нижних углов\n",
        "    intersect_maxes = K.minimum(right_bottom1, right_bottom2) \n",
        "    \n",
        "    # Считаем ширину и высоту области пересечения\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.) \n",
        "    \n",
        "    # Считаем площадь области пересечения\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1] \n",
        "    \n",
        "    # Считаем площадь первых элементов\n",
        "    area1 = wh1[..., 0] * wh1[..., 1] \n",
        "\n",
        "    # Считаем площадь вторых элементов\n",
        "    area2 = wh2[..., 0] * wh2[..., 1] \n",
        "    \n",
        "    return intersect_area / (area1 + area2 - intersect_area) "
      ],
      "metadata": {
        "id": "n_r1_AhzOt8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_y(true_boxes, anchors, input_shape):\n",
        "    \n",
        "    ''' Функция подсчета y\n",
        "        Args: \n",
        "            true_boxes -\n",
        "            anchors -\n",
        "            input_shape - \n",
        "        Return:\n",
        "            ???\n",
        "\n",
        "        '''\n",
        "    # Получаем количество анкоров для каждого уровня сеток\n",
        "    num_layers = len(anchors) // 3 \n",
        "    \n",
        "    # Задаем маску анкоров для каждого уровня\n",
        "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] \n",
        "    \n",
        "    # Преобразуем bounding_box в numpy\n",
        "    true_boxes = np.array(true_boxes, dtype='float32') \n",
        "\n",
        "    # Преобразуем input_shape в numpy\n",
        "    input_shape = np.array(input_shape, dtype='int32') \n",
        "\n",
        "    # Получаем координаты центра bounding_box (xRight+xLeft / 2)\n",
        "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2 \n",
        "\n",
        "    # Получаем ширину и высоту bounding_box (xRight - xLeft)\n",
        "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2] \n",
        "\n",
        "    # Получаем координаты центра bounding_box в относительных координатах\n",
        "    true_boxes[..., 0:2] = boxes_xy / input_shape[::-1] \n",
        "\n",
        "    # Получаем высоту и ширину bounding_box В относительных значениях\n",
        "    true_boxes[..., 2:4] = boxes_wh / input_shape[::-1] \n",
        "\n",
        "    # Получаем количество элементов в batch_size\n",
        "    m = true_boxes.shape[0] \n",
        "\n",
        "    # Создаем список из трех элементов ([13, 13], [26, 26], [52, 52])\n",
        "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)] \n",
        "\n",
        "    # Создаем 0-вые списки для y_true\n",
        "    # y_true[0].shape = (None, 13, 13, 3, 6)\n",
        "    # y_true[1].shape = (None, 26, 26, 3, 6)\n",
        "    # y_true[2].shape = (None, 52, 52, 3, 6)\n",
        "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
        "        dtype='float32') for l in range(num_layers)]\n",
        "\n",
        "    anchors = np.expand_dims(anchors, 0) # Добавляем размерность\n",
        "\n",
        "    # Параметры для IoU\n",
        "    anchor_maxes = anchors / 2. \n",
        "    anchor_mins = -anchor_maxes\n",
        "    valid_mask = boxes_wh[..., 0] > 0\n",
        "\n",
        "    for b in range(m):\n",
        "        \n",
        "        wh = boxes_wh[b, valid_mask[b]] # Получаем ширину и высоту текущего bounding_box\n",
        "        \n",
        "        if len(wh)==0: continue # Выходим если она нулевая\n",
        "        \n",
        "        wh = np.expand_dims(wh, -2) # Добавляем размерность\n",
        "        \n",
        "        # Параметры для IoU\n",
        "        box_maxes = wh / 2.\n",
        "        box_mins = -box_maxes\n",
        "        \n",
        "        intersect_mins = np.maximum(box_mins, anchor_mins) \n",
        "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
        "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "        box_area = wh[..., 0] * wh[..., 1]\n",
        "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
        "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
        "\n",
        "        best_anchor = np.argmax(iou, axis=-1) # Находим лучшее значение iou для всех анкоров \n",
        "\n",
        "        for t, n in enumerate(best_anchor): \n",
        "            \n",
        "            for l in range(num_layers):\n",
        "                \n",
        "                if n in anchor_mask[l]:\n",
        "                    i = np.floor(true_boxes[b,t,0] * grid_shapes[l][1]).astype('int32')\n",
        "                    j = np.floor(true_boxes[b,t,1] * grid_shapes[l][0]).astype('int32')\n",
        "                    k = anchor_mask[l].index(n)\n",
        "                    c = true_boxes[b,t, 4].astype('int32')\n",
        "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
        "                    y_true[l][b, j, i, k, 4] = 1\n",
        "                    y_true[l][b, j, i, k, 5+c] = 1\n",
        "    \n",
        "    return y_true"
      ],
      "metadata": {
        "id": "VndcR4x9Rz6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rand(a=0, b=1):\n",
        "    \n",
        "    return np.random.rand()*(b-a) + a"
      ],
      "metadata": {
        "id": "7gbp5nA3mvDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWxqm59sZ-Ye"
      },
      "source": [
        "def augmentation(data):\n",
        "    \n",
        "    ''' Функция случайной аугментации данных\n",
        "        Args: \n",
        "            data - изображения \n",
        "        Return:\n",
        "            аугментированные изображение и bounding_box\n",
        "\n",
        "        '''\n",
        "\n",
        "    # Словарь с параметрами аугментации\n",
        "    params = {\n",
        "        'jitter' : .3,\n",
        "        'hue'    : .1,\n",
        "        'sat'    : 1.5,\n",
        "        'val'    : 1.5\n",
        "    }\n",
        "    \n",
        "    # Сплитим входную строку словаря\n",
        "    data = data.split() \n",
        "    # Открываем изображение самолета\n",
        "    image = Image.open(data[0]) \n",
        "    \n",
        "    # Получаем ширину и высоту оригинального изображения\n",
        "    width_i, height_i = image.size \n",
        "    \n",
        "    # Получаем ширину и высоту входного изображения для модели RetinaNet\n",
        "    widht_shape, height_shape = (416, 416)\n",
        "    \n",
        "    # Получаем координаты ограничивающей рамки\n",
        "    box = np.array([np.array(list(map(lambda x: int(float(x)),box.split(',')))) for box in data[1:]])\n",
        "    \n",
        "    # Случайным образом масштабируем изображение\n",
        "    new_ar = widht_shape / height_shape * rand(1 - params['jitter'], 1 + params['jitter']) / rand(1 - params['jitter'], 1 + params['jitter'])\n",
        "    scale = rand(.65, 2) \n",
        "    if new_ar < 1:        \n",
        "        nh = int(scale * height_shape)\n",
        "        nw = int(nh * new_ar)\n",
        "    else:\n",
        "        nw = int(scale * widht_shape)\n",
        "        nh = int(nw / new_ar)\n",
        "    image = image.resize((nw, nh), Image.BICUBIC)\n",
        "    \n",
        "    # Преобразуем картинку к input_shape и размещаем случайным образом\n",
        "    dx = int(rand(0, widht_shape - nw))\n",
        "    dy = int(rand(0, height_shape - nh))\n",
        "    new_image = Image.new('RGB', (widht_shape, height_shape), (128,128,128))\n",
        "    new_image.paste(image, (dx, dy))\n",
        "    image = new_image\n",
        "    \n",
        "    # С вероятностью 50% отображаем по горизонтале\n",
        "    flip = rand() < .5\n",
        "    if flip:\n",
        "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    \n",
        "    # Случайным образом меняем освещенность, экспозицию, гамму изображения\n",
        "    hue1 = rand(-params['hue'], params['hue'])\n",
        "    sat1 = rand(1, params['sat']) if rand() < .5 else 1 / rand(1, params['sat'])\n",
        "    val1 = rand(1, params['val']) if rand() < .5 else 1 / rand(1, params['val'])\n",
        "    x = rgb_to_hsv(np.array(image) / 255.)\n",
        "    x[..., 0] += hue1\n",
        "    x[..., 0][x[..., 0] > 1] -= 1\n",
        "    x[..., 0][x[..., 0] < 0] += 1\n",
        "    x[..., 1] *= sat1\n",
        "    x[..., 2] *= val1\n",
        "    x[x > 1] = 1\n",
        "    x[x < 0] = 0\n",
        "    image_data = hsv_to_rgb(x) # Получаем окончательный массив\n",
        "    \n",
        "    max_boxes = 4 # Устанавливаем максимальное количество рамок на изображении\n",
        "    \n",
        "    # Корректируем параметры ограничивающей рамки в соответсвии с проведенными выше преобразованиями\n",
        "    box_data = np.zeros((max_boxes,5)) # Создаем массив из нулей размерностью (max_boxes, 5) \n",
        "    \n",
        "    if len(box)>0:                \n",
        "        # Ресайзим и перемещаем\n",
        "        box[:, [0,2]] = box[:, [0,2]] * nw/width_i + dx\n",
        "        box[:, [1,3]] = box[:, [1,3]] * nh/height_i + dy\n",
        "        \n",
        "        # Отражаем по горизонтале\n",
        "        if flip: box[:, [0,2]] = widht_shape - box[:, [2,0]]\n",
        "        box[:, 0:2][box[:, 0:2]<0] = 0\n",
        "        \n",
        "        # Ограничиваем, если вышли за пределы input_shape\n",
        "        box[:, 2][box[:, 2] > widht_shape] = widht_shape\n",
        "        box[:, 3][box[:, 3] > height_shape] = height_shape\n",
        "        \n",
        "        # Считаем высоту и ширину рамок и оставляем только те, значения которых больше 1\n",
        "        box_w = box[:, 2] - box[:, 0] # xRight - xLeft\n",
        "        box_h = box[:, 3] - box[:, 1] # yBottom - yTop\n",
        "        box = box[np.logical_and(box_w > 1, box_h > 1)]\n",
        "        \n",
        "        if len(box) > max_boxes: # Оставляем только max_boxes рамок\n",
        "            box = box[:max_boxes]\n",
        "        box_data[:len(box)] = box # Записываем данные в box_data\n",
        "    \n",
        "    return image_data, box_data # Возвращаем аугментированные изображение и bounding_box  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(annotation_lines, batch_size, anchors, input_shape):\n",
        "    \n",
        "    ''' Функция генерации данных\n",
        "        Args: \n",
        "            annotation_lines -\n",
        "            batch_size -\n",
        "            anchors - \n",
        "            input_shape -\n",
        "        Return:\n",
        "            порция данных для обучения \n",
        "\n",
        "        '''\n",
        "\n",
        "    n = len(annotation_lines) # Получаем количество элементов в словаре аннотаций\n",
        "    i = 0 # Задаем начальный индекс\n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        image_data = [] # Массив для хранения изображений 416х416\n",
        "        box_data = [] # Массив для хранения bounding_box данных\n",
        "        \n",
        "        for b in range(batch_size): # Пробегаем по всему batch_size\n",
        "            \n",
        "            if i==0: # Если первая итерация цикла\n",
        "                np.random.shuffle(annotation_lines) # Перемешиваем элементы\n",
        "            \n",
        "            # Делаем аугментацию картинок и ограничивающих рамок\n",
        "            image, box = augmentation(annotation_lines[i]) \n",
        "            \n",
        "            # Добавляем полученную картинку в результирующий массив \n",
        "            image_data.append(image) \n",
        "            \n",
        "            # Добавляем полученную ограничивающую рамку в массив bounfing_box\n",
        "            box_data.append(box) \n",
        "            \n",
        "            # Обновляем значение индека (не превышая общего количества элементов)\n",
        "            i = (i+1) % n \n",
        "        \n",
        "        # Преобразуем в numpy\n",
        "        image_data = np.array(image_data)         \n",
        "        box_data = np.array(box_data) \n",
        "        \n",
        "        # По значению ограничивающей рамки получаем y_true \n",
        "        y_true = get_y(box_data, anchors, input_shape)        \n",
        "        \n",
        "        yield [image_data, *y_true], np.zeros(batch_size) "
      ],
      "metadata": {
        "id": "S4gDibQ2Qg33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функция create_model"
      ],
      "metadata": {
        "id": "2f2Yw916VDX-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVjCtDY4IbM5"
      },
      "source": [
        "Функция `create_model` оборачивает модель YOLO для обучения. Мы создаем три входных слоя y_true с формой тезоров ((None, 13, 13, 3, 6), (None, 26, 26, 3, 6) и (None, 52, 52, 3, 6)), где:\n",
        "- Первая позиция (None) - размерность под размер пакета (batch)\n",
        "- Вторая и третья позиции (13, 13) указывают размерность сетки (якорного поля), на которую условно будет разбито входное изображение. Каждый уровень сетки отвечает за обнаружение объектов различных размеров (13 - крупных, 26 - средних, 52 - мелких)\n",
        "- Четвертая позиция - (3)количество анкоров на каждый уровень сетки\n",
        "- Пятая позиция - (6) из них 4 параметра описывающие параметры базового анкора (координаты центра, ширина и высота) +1 вероятность обнаружения объекта + 1 OHE номер класса (так как класс в датасете всего 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx_nR1su9guF"
      },
      "source": [
        "def create_model(size, num_anchors, use_weights = False, weights_path = weights_path ):\n",
        "\n",
        "    ''' Функция оборачивает модель YOLO для обучения\n",
        "\n",
        "        Args:\n",
        "            input_shape - размерность входного изображения для модели YOLO\n",
        "            num_anchors - общее количество анкоров (9)\n",
        "            use_weights - использовать ли предобученные веса(если модель уже начали обучать)\n",
        "            weights_path - путь к сохраненным весам модели\n",
        "        Return:\n",
        "            созданная модель  \n",
        "            \n",
        "            '''   \n",
        "    # Создаем входной слой модели, добавляя размерность для глубины цвета\n",
        "    inputs = Input(shape = (size, size, 3)) \n",
        "    \n",
        "    y_true    =   [Input (shape = (size // 32, size // 32, num_anchors // 3, num_classes + 5))] # Уровень сетки 13х13 (416/32)\n",
        "    y_true.append (Input (shape = (size // 16, size // 16, num_anchors // 3, num_classes + 5))) # Уровень сетки 26х26 (416/26)\n",
        "    y_true.append (Input (shape = (size // 8,  size // 8,  num_anchors // 3, num_classes + 5))) # Уровень сетки 52х52 (416/8)\n",
        "    \n",
        "    # Создаем модель YOLOv3\n",
        "    model_yolo = create_yolov3_model(inputs, num_anchors // 3, num_classes) \n",
        "    \n",
        "    # Выводим сообщение о создании модели\n",
        "    print ('Создана модель YOLOv3. Количество классов: {}.'.format(num_classes)) \n",
        "    \n",
        "    # Если установлен флаг загрузки весов\n",
        "    if use_weights:\n",
        "\n",
        "        # Загружаем предобученные веса\n",
        "        model_yolo.load_weights(weights_path, by_name = False, skip_mismatch = False) \n",
        "        # Выводим сообщение о загруженных весах\n",
        "        print ('Загружены веса из файла {}.'.format(weights_path)) \n",
        "        \n",
        "    # Создаем выходной слой Lambda (выходом которого будет значение ошибки модели)\n",
        "    # На вход слоя подается:\n",
        "    #   - model_yolo.output (выход модели model_yolo (то есть то, что посчитала сеть))\n",
        "    #   - y_true (оригинальные данные из обучающей выборки)\n",
        "    outputs = Lambda(yolo_loss, output_shape = (1,), name = 'yolo_loss', arguments = {'num_anchors' : num_anchors}) ([*model_yolo.output, *y_true])\n",
        "    \n",
        "    # Возвращаем модель\n",
        "    return Model([inputs, *y_true], outputs) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZyrikE9y_nk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dcfeae-690c-42d5-c7e5-8b00ad362f1d"
      },
      "source": [
        "# Создаем модель\n",
        "model_YOLO = create_model(size, num_anchors, use_weights=False, weights_path=weights_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создана модель YOLOv3. Количество классов: 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZkgF6j4-IiE",
        "outputId": "781b9e3b-9e42-45eb-d927-00d22a26700d"
      },
      "source": [
        "print('Выводим входные размерности для модели', model_YOLO.input)\n",
        "print()\n",
        "print('Выводим выходную размерность модели', model_YOLO.output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выводим входные размерности для модели [<KerasTensor: shape=(None, 416, 416, 3) dtype=float32 (created by layer 'input_10')>, <KerasTensor: shape=(None, 13, 13, 3, 6) dtype=float32 (created by layer 'input_11')>, <KerasTensor: shape=(None, 26, 26, 3, 6) dtype=float32 (created by layer 'input_12')>, <KerasTensor: shape=(None, 52, 52, 3, 6) dtype=float32 (created by layer 'input_13')>]\n",
            "\n",
            "Выводим выходную размерность модели KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='yolo_loss/add_17:0', description=\"created by layer 'yolo_loss'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP0ejQQZ-XjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9933b087-9159-4c42-dcaf-28f9f6b972f7"
      },
      "source": [
        "# Выводим информацию о модели\n",
        "model_YOLO.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 416, 416, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv_0 (Conv2D)                (None, 416, 416, 32  864         ['input_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_0 (BatchNormalization)   (None, 416, 416, 32  128         ['conv_0[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_0 (LeakyReLU)            (None, 416, 416, 32  0           ['bnorm_0[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_10 (ZeroPadding  (None, 417, 417, 32  0          ['leake_0[0][0]']                \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv_1 (Conv2D)                (None, 208, 208, 64  18432       ['zero_padding2d_10[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_1 (BatchNormalization)   (None, 208, 208, 64  256         ['conv_1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_1 (LeakyReLU)            (None, 208, 208, 64  0           ['bnorm_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_2 (Conv2D)                (None, 208, 208, 32  2048        ['leake_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_2 (BatchNormalization)   (None, 208, 208, 32  128         ['conv_2[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_2 (LeakyReLU)            (None, 208, 208, 32  0           ['bnorm_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_3 (Conv2D)                (None, 208, 208, 64  18432       ['leake_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_3 (BatchNormalization)   (None, 208, 208, 64  256         ['conv_3[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_3 (LeakyReLU)            (None, 208, 208, 64  0           ['bnorm_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Add_4 (Add)                    (None, 208, 208, 64  0           ['leake_1[0][0]',                \n",
            "                                )                                 'leake_3[0][0]']                \n",
            "                                                                                                  \n",
            " zero_padding2d_11 (ZeroPadding  (None, 209, 209, 64  0          ['Add_4[0][0]']                  \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv_5 (Conv2D)                (None, 104, 104, 12  73728       ['zero_padding2d_11[0][0]']      \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " bnorm_5 (BatchNormalization)   (None, 104, 104, 12  512         ['conv_5[0][0]']                 \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " leake_5 (LeakyReLU)            (None, 104, 104, 12  0           ['bnorm_5[0][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv_6 (Conv2D)                (None, 104, 104, 64  8192        ['leake_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_6 (BatchNormalization)   (None, 104, 104, 64  256         ['conv_6[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_6 (LeakyReLU)            (None, 104, 104, 64  0           ['bnorm_6[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_7 (Conv2D)                (None, 104, 104, 12  73728       ['leake_6[0][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " bnorm_7 (BatchNormalization)   (None, 104, 104, 12  512         ['conv_7[0][0]']                 \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " leake_7 (LeakyReLU)            (None, 104, 104, 12  0           ['bnorm_7[0][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " Add_8 (Add)                    (None, 104, 104, 12  0           ['leake_5[0][0]',                \n",
            "                                8)                                'leake_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv_9 (Conv2D)                (None, 104, 104, 64  8192        ['Add_8[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_9 (BatchNormalization)   (None, 104, 104, 64  256         ['conv_9[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_9 (LeakyReLU)            (None, 104, 104, 64  0           ['bnorm_9[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_10 (Conv2D)               (None, 104, 104, 12  73728       ['leake_9[0][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " bnorm_10 (BatchNormalization)  (None, 104, 104, 12  512         ['conv_10[0][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " leake_10 (LeakyReLU)           (None, 104, 104, 12  0           ['bnorm_10[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " Add_11 (Add)                   (None, 104, 104, 12  0           ['Add_8[0][0]',                  \n",
            "                                8)                                'leake_10[0][0]']               \n",
            "                                                                                                  \n",
            " zero_padding2d_12 (ZeroPadding  (None, 105, 105, 12  0          ['Add_11[0][0]']                 \n",
            " 2D)                            8)                                                                \n",
            "                                                                                                  \n",
            " conv_12 (Conv2D)               (None, 52, 52, 256)  294912      ['zero_padding2d_12[0][0]']      \n",
            "                                                                                                  \n",
            " bnorm_12 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_12[0][0]']                \n",
            "                                                                                                  \n",
            " leake_12 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv_13 (Conv2D)               (None, 52, 52, 128)  32768       ['leake_12[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_13 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_13[0][0]']                \n",
            "                                                                                                  \n",
            " leake_13 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv_14 (Conv2D)               (None, 52, 52, 256)  294912      ['leake_13[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_14 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_14[0][0]']                \n",
            "                                                                                                  \n",
            " leake_14 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_14[0][0]']               \n",
            "                                                                                                  \n",
            " Add_15 (Add)                   (None, 52, 52, 256)  0           ['leake_12[0][0]',               \n",
            "                                                                  'leake_14[0][0]']               \n",
            "                                                                                                  \n",
            " conv_16 (Conv2D)               (None, 52, 52, 128)  32768       ['Add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_16 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_16[0][0]']                \n",
            "                                                                                                  \n",
            " leake_16 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv_17 (Conv2D)               (None, 52, 52, 256)  294912      ['leake_16[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_17 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_17[0][0]']                \n",
            "                                                                                                  \n",
            " leake_17 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_17[0][0]']               \n",
            "                                                                                                  \n",
            " Add_18 (Add)                   (None, 52, 52, 256)  0           ['Add_15[0][0]',                 \n",
            "                                                                  'leake_17[0][0]']               \n",
            "                                                                                                  \n",
            " conv_19 (Conv2D)               (None, 52, 52, 128)  32768       ['Add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_19 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_19[0][0]']                \n",
            "                                                                                                  \n",
            " leake_19 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv_20 (Conv2D)               (None, 52, 52, 256)  294912      ['leake_19[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_20 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_20[0][0]']                \n",
            "                                                                                                  \n",
            " leake_20 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_20[0][0]']               \n",
            "                                                                                                  \n",
            " Add_21 (Add)                   (None, 52, 52, 256)  0           ['Add_18[0][0]',                 \n",
            "                                                                  'leake_20[0][0]']               \n",
            "                                                                                                  \n",
            " conv_22 (Conv2D)               (None, 52, 52, 128)  32768       ['Add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_22 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_22[0][0]']                \n",
            "                                                                                                  \n",
            " leake_22 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv_23 (Conv2D)               (None, 52, 52, 256)  294912      ['leake_22[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_23 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_23[0][0]']                \n",
            "                                                                                                  \n",
            " leake_23 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_23[0][0]']               \n",
            "                                                                                                  \n",
            " Add_24 (Add)                   (None, 52, 52, 256)  0           ['Add_21[0][0]',                 \n",
            "                                                                  'leake_23[0][0]']               \n",
            "                                                                                                  \n",
            " conv_25 (Conv2D)               (None, 52, 52, 128)  32768       ['Add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_25 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_25[0][0]']                \n",
            "                                                                                                  \n",
            " leake_25 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv_26 (Conv2D)               (None, 52, 52, 256)  294912      ['leake_25[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_26 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_26[0][0]']                \n",
            "                                                                                                  \n",
            " leake_26 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_26[0][0]']               \n",
            "                                                                                                  \n",
            " Add_27 (Add)                   (None, 52, 52, 256)  0           ['Add_24[0][0]',                 \n",
            "                                                                  'leake_26[0][0]']               \n",
            "                                                                                                  \n",
            " conv_28 (Conv2D)               (None, 52, 52, 128)  32768       ['Add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_28 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_28[0][0]']                \n",
            "                                                                                                  \n",
            " leake_28 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv_29 (Conv2D)               (None, 52, 52, 256)  294912      ['leake_28[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_29 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_29[0][0]']                \n",
            "                                                                                                  \n",
            " leake_29 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_29[0][0]']               \n",
            "                                                                                                  \n",
            " Add_30 (Add)                   (None, 52, 52, 256)  0           ['Add_27[0][0]',                 \n",
            "                                                                  'leake_29[0][0]']               \n",
            "                                                                                                  \n",
            " conv_31 (Conv2D)               (None, 52, 52, 128)  32768       ['Add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_31 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_31[0][0]']                \n",
            "                                                                                                  \n",
            " leake_31 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv_32 (Conv2D)               (None, 52, 52, 256)  294912      ['leake_31[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_32 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_32[0][0]']                \n",
            "                                                                                                  \n",
            " leake_32 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_32[0][0]']               \n",
            "                                                                                                  \n",
            " Add_33 (Add)                   (None, 52, 52, 256)  0           ['Add_30[0][0]',                 \n",
            "                                                                  'leake_32[0][0]']               \n",
            "                                                                                                  \n",
            " conv_34 (Conv2D)               (None, 52, 52, 128)  32768       ['Add_33[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_34 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_34[0][0]']                \n",
            "                                                                                                  \n",
            " leake_34 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv_35 (Conv2D)               (None, 52, 52, 256)  294912      ['leake_34[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_35 (BatchNormalization)  (None, 52, 52, 256)  1024        ['conv_35[0][0]']                \n",
            "                                                                                                  \n",
            " leake_35 (LeakyReLU)           (None, 52, 52, 256)  0           ['bnorm_35[0][0]']               \n",
            "                                                                                                  \n",
            " Add_36 (Add)                   (None, 52, 52, 256)  0           ['Add_33[0][0]',                 \n",
            "                                                                  'leake_35[0][0]']               \n",
            "                                                                                                  \n",
            " zero_padding2d_13 (ZeroPadding  (None, 53, 53, 256)  0          ['Add_36[0][0]']                 \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv_37 (Conv2D)               (None, 26, 26, 512)  1179648     ['zero_padding2d_13[0][0]']      \n",
            "                                                                                                  \n",
            " bnorm_37 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_37[0][0]']                \n",
            "                                                                                                  \n",
            " leake_37 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv_38 (Conv2D)               (None, 26, 26, 256)  131072      ['leake_37[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_38 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_38[0][0]']                \n",
            "                                                                                                  \n",
            " leake_38 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_38[0][0]']               \n",
            "                                                                                                  \n",
            " conv_39 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_38[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_39 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_39[0][0]']                \n",
            "                                                                                                  \n",
            " leake_39 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_39[0][0]']               \n",
            "                                                                                                  \n",
            " Add_40 (Add)                   (None, 26, 26, 512)  0           ['leake_37[0][0]',               \n",
            "                                                                  'leake_39[0][0]']               \n",
            "                                                                                                  \n",
            " conv_41 (Conv2D)               (None, 26, 26, 256)  131072      ['Add_40[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_41 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_41[0][0]']                \n",
            "                                                                                                  \n",
            " leake_41 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_41[0][0]']               \n",
            "                                                                                                  \n",
            " conv_42 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_41[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_42 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_42[0][0]']                \n",
            "                                                                                                  \n",
            " leake_42 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_42[0][0]']               \n",
            "                                                                                                  \n",
            " Add_43 (Add)                   (None, 26, 26, 512)  0           ['Add_40[0][0]',                 \n",
            "                                                                  'leake_42[0][0]']               \n",
            "                                                                                                  \n",
            " conv_44 (Conv2D)               (None, 26, 26, 256)  131072      ['Add_43[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_44 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_44[0][0]']                \n",
            "                                                                                                  \n",
            " leake_44 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_44[0][0]']               \n",
            "                                                                                                  \n",
            " conv_45 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_44[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_45 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_45[0][0]']                \n",
            "                                                                                                  \n",
            " leake_45 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_45[0][0]']               \n",
            "                                                                                                  \n",
            " Add_46 (Add)                   (None, 26, 26, 512)  0           ['Add_43[0][0]',                 \n",
            "                                                                  'leake_45[0][0]']               \n",
            "                                                                                                  \n",
            " conv_47 (Conv2D)               (None, 26, 26, 256)  131072      ['Add_46[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_47 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_47[0][0]']                \n",
            "                                                                                                  \n",
            " leake_47 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_47[0][0]']               \n",
            "                                                                                                  \n",
            " conv_48 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_47[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_48 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_48[0][0]']                \n",
            "                                                                                                  \n",
            " leake_48 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_48[0][0]']               \n",
            "                                                                                                  \n",
            " Add_49 (Add)                   (None, 26, 26, 512)  0           ['Add_46[0][0]',                 \n",
            "                                                                  'leake_48[0][0]']               \n",
            "                                                                                                  \n",
            " conv_50 (Conv2D)               (None, 26, 26, 256)  131072      ['Add_49[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_50 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_50[0][0]']                \n",
            "                                                                                                  \n",
            " leake_50 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv_51 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_50[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_51 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_51[0][0]']                \n",
            "                                                                                                  \n",
            " leake_51 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_51[0][0]']               \n",
            "                                                                                                  \n",
            " Add_52 (Add)                   (None, 26, 26, 512)  0           ['Add_49[0][0]',                 \n",
            "                                                                  'leake_51[0][0]']               \n",
            "                                                                                                  \n",
            " conv_53 (Conv2D)               (None, 26, 26, 256)  131072      ['Add_52[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_53 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_53[0][0]']                \n",
            "                                                                                                  \n",
            " leake_53 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv_54 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_53[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_54 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_54[0][0]']                \n",
            "                                                                                                  \n",
            " leake_54 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_54[0][0]']               \n",
            "                                                                                                  \n",
            " Add_55 (Add)                   (None, 26, 26, 512)  0           ['Add_52[0][0]',                 \n",
            "                                                                  'leake_54[0][0]']               \n",
            "                                                                                                  \n",
            " conv_56 (Conv2D)               (None, 26, 26, 256)  131072      ['Add_55[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_56 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_56[0][0]']                \n",
            "                                                                                                  \n",
            " leake_56 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv_57 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_56[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_57 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_57[0][0]']                \n",
            "                                                                                                  \n",
            " leake_57 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_57[0][0]']               \n",
            "                                                                                                  \n",
            " Add_58 (Add)                   (None, 26, 26, 512)  0           ['Add_55[0][0]',                 \n",
            "                                                                  'leake_57[0][0]']               \n",
            "                                                                                                  \n",
            " conv_59 (Conv2D)               (None, 26, 26, 256)  131072      ['Add_58[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_59 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_59[0][0]']                \n",
            "                                                                                                  \n",
            " leake_59 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv_60 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_59[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_60 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_60[0][0]']                \n",
            "                                                                                                  \n",
            " leake_60 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_60[0][0]']               \n",
            "                                                                                                  \n",
            " Add_61 (Add)                   (None, 26, 26, 512)  0           ['Add_58[0][0]',                 \n",
            "                                                                  'leake_60[0][0]']               \n",
            "                                                                                                  \n",
            " zero_padding2d_14 (ZeroPadding  (None, 27, 27, 512)  0          ['Add_61[0][0]']                 \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv_62 (Conv2D)               (None, 13, 13, 1024  4718592     ['zero_padding2d_14[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_62 (BatchNormalization)  (None, 13, 13, 1024  4096        ['conv_62[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_62 (LeakyReLU)           (None, 13, 13, 1024  0           ['bnorm_62[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_63 (Conv2D)               (None, 13, 13, 512)  524288      ['leake_62[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_63 (BatchNormalization)  (None, 13, 13, 512)  2048        ['conv_63[0][0]']                \n",
            "                                                                                                  \n",
            " leake_63 (LeakyReLU)           (None, 13, 13, 512)  0           ['bnorm_63[0][0]']               \n",
            "                                                                                                  \n",
            " conv_64 (Conv2D)               (None, 13, 13, 1024  4718592     ['leake_63[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_64 (BatchNormalization)  (None, 13, 13, 1024  4096        ['conv_64[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_64 (LeakyReLU)           (None, 13, 13, 1024  0           ['bnorm_64[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Add_65 (Add)                   (None, 13, 13, 1024  0           ['leake_62[0][0]',               \n",
            "                                )                                 'leake_64[0][0]']               \n",
            "                                                                                                  \n",
            " conv_66 (Conv2D)               (None, 13, 13, 512)  524288      ['Add_65[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_66 (BatchNormalization)  (None, 13, 13, 512)  2048        ['conv_66[0][0]']                \n",
            "                                                                                                  \n",
            " leake_66 (LeakyReLU)           (None, 13, 13, 512)  0           ['bnorm_66[0][0]']               \n",
            "                                                                                                  \n",
            " conv_67 (Conv2D)               (None, 13, 13, 1024  4718592     ['leake_66[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_67 (BatchNormalization)  (None, 13, 13, 1024  4096        ['conv_67[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_67 (LeakyReLU)           (None, 13, 13, 1024  0           ['bnorm_67[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Add_68 (Add)                   (None, 13, 13, 1024  0           ['Add_65[0][0]',                 \n",
            "                                )                                 'leake_67[0][0]']               \n",
            "                                                                                                  \n",
            " conv_69 (Conv2D)               (None, 13, 13, 512)  524288      ['Add_68[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_69 (BatchNormalization)  (None, 13, 13, 512)  2048        ['conv_69[0][0]']                \n",
            "                                                                                                  \n",
            " leake_69 (LeakyReLU)           (None, 13, 13, 512)  0           ['bnorm_69[0][0]']               \n",
            "                                                                                                  \n",
            " conv_70 (Conv2D)               (None, 13, 13, 1024  4718592     ['leake_69[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_70 (BatchNormalization)  (None, 13, 13, 1024  4096        ['conv_70[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_70 (LeakyReLU)           (None, 13, 13, 1024  0           ['bnorm_70[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Add_71 (Add)                   (None, 13, 13, 1024  0           ['Add_68[0][0]',                 \n",
            "                                )                                 'leake_70[0][0]']               \n",
            "                                                                                                  \n",
            " conv_72 (Conv2D)               (None, 13, 13, 512)  524288      ['Add_71[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_72 (BatchNormalization)  (None, 13, 13, 512)  2048        ['conv_72[0][0]']                \n",
            "                                                                                                  \n",
            " leake_72 (LeakyReLU)           (None, 13, 13, 512)  0           ['bnorm_72[0][0]']               \n",
            "                                                                                                  \n",
            " conv_73 (Conv2D)               (None, 13, 13, 1024  4718592     ['leake_72[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_73 (BatchNormalization)  (None, 13, 13, 1024  4096        ['conv_73[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_73 (LeakyReLU)           (None, 13, 13, 1024  0           ['bnorm_73[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Add_74 (Add)                   (None, 13, 13, 1024  0           ['Add_71[0][0]',                 \n",
            "                                )                                 'leake_73[0][0]']               \n",
            "                                                                                                  \n",
            " conv_75 (Conv2D)               (None, 13, 13, 512)  524288      ['Add_74[0][0]']                 \n",
            "                                                                                                  \n",
            " bnorm_75 (BatchNormalization)  (None, 13, 13, 512)  2048        ['conv_75[0][0]']                \n",
            "                                                                                                  \n",
            " leake_75 (LeakyReLU)           (None, 13, 13, 512)  0           ['bnorm_75[0][0]']               \n",
            "                                                                                                  \n",
            " conv_76 (Conv2D)               (None, 13, 13, 1024  4718592     ['leake_75[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_76 (BatchNormalization)  (None, 13, 13, 1024  4096        ['conv_76[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_76 (LeakyReLU)           (None, 13, 13, 1024  0           ['bnorm_76[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_77 (Conv2D)               (None, 13, 13, 512)  524288      ['leake_76[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_77 (BatchNormalization)  (None, 13, 13, 512)  2048        ['conv_77[0][0]']                \n",
            "                                                                                                  \n",
            " leake_77 (LeakyReLU)           (None, 13, 13, 512)  0           ['bnorm_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv_78 (Conv2D)               (None, 13, 13, 1024  4718592     ['leake_77[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_78 (BatchNormalization)  (None, 13, 13, 1024  4096        ['conv_78[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_78 (LeakyReLU)           (None, 13, 13, 1024  0           ['bnorm_78[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_79 (Conv2D)               (None, 13, 13, 512)  524288      ['leake_78[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_79 (BatchNormalization)  (None, 13, 13, 512)  2048        ['conv_79[0][0]']                \n",
            "                                                                                                  \n",
            " leake_79 (LeakyReLU)           (None, 13, 13, 512)  0           ['bnorm_79[0][0]']               \n",
            "                                                                                                  \n",
            " conv_84 (Conv2D)               (None, 13, 13, 256)  131072      ['leake_79[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_84 (BatchNormalization)  (None, 13, 13, 256)  1024        ['conv_84[0][0]']                \n",
            "                                                                                                  \n",
            " leake_84 (LeakyReLU)           (None, 13, 13, 256)  0           ['bnorm_84[0][0]']               \n",
            "                                                                                                  \n",
            " UpSampling_85 (UpSampling2D)   (None, 26, 26, 256)  0           ['leake_84[0][0]']               \n",
            "                                                                                                  \n",
            " Concatenate_86 (Concatenate)   (None, 26, 26, 768)  0           ['UpSampling_85[0][0]',          \n",
            "                                                                  'Add_61[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_87 (Conv2D)               (None, 26, 26, 256)  196608      ['Concatenate_86[0][0]']         \n",
            "                                                                                                  \n",
            " bnorm_87 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_87[0][0]']                \n",
            "                                                                                                  \n",
            " leake_87 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_87[0][0]']               \n",
            "                                                                                                  \n",
            " conv_88 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_87[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_88 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_88[0][0]']                \n",
            "                                                                                                  \n",
            " leake_88 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_88[0][0]']               \n",
            "                                                                                                  \n",
            " conv_89 (Conv2D)               (None, 26, 26, 256)  131072      ['leake_88[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_89 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_89[0][0]']                \n",
            "                                                                                                  \n",
            " leake_89 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv_90 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_89[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_90 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_90[0][0]']                \n",
            "                                                                                                  \n",
            " leake_90 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_90[0][0]']               \n",
            "                                                                                                  \n",
            " conv_91 (Conv2D)               (None, 26, 26, 256)  131072      ['leake_90[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_91 (BatchNormalization)  (None, 26, 26, 256)  1024        ['conv_91[0][0]']                \n",
            "                                                                                                  \n",
            " leake_91 (LeakyReLU)           (None, 26, 26, 256)  0           ['bnorm_91[0][0]']               \n",
            "                                                                                                  \n",
            " conv_96 (Conv2D)               (None, 26, 26, 128)  32768       ['leake_91[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_96 (BatchNormalization)  (None, 26, 26, 128)  512         ['conv_96[0][0]']                \n",
            "                                                                                                  \n",
            " leake_96 (LeakyReLU)           (None, 26, 26, 128)  0           ['bnorm_96[0][0]']               \n",
            "                                                                                                  \n",
            " UpSampling_97 (UpSampling2D)   (None, 52, 52, 128)  0           ['leake_96[0][0]']               \n",
            "                                                                                                  \n",
            " Concatenate_98 (Concatenate)   (None, 52, 52, 384)  0           ['UpSampling_97[0][0]',          \n",
            "                                                                  'Add_36[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_99 (Conv2D)               (None, 52, 52, 128)  49152       ['Concatenate_98[0][0]']         \n",
            "                                                                                                  \n",
            " bnorm_99 (BatchNormalization)  (None, 52, 52, 128)  512         ['conv_99[0][0]']                \n",
            "                                                                                                  \n",
            " leake_99 (LeakyReLU)           (None, 52, 52, 128)  0           ['bnorm_99[0][0]']               \n",
            "                                                                                                  \n",
            " conv_100 (Conv2D)              (None, 52, 52, 256)  294912      ['leake_99[0][0]']               \n",
            "                                                                                                  \n",
            " bnorm_100 (BatchNormalization)  (None, 52, 52, 256)  1024       ['conv_100[0][0]']               \n",
            "                                                                                                  \n",
            " leake_100 (LeakyReLU)          (None, 52, 52, 256)  0           ['bnorm_100[0][0]']              \n",
            "                                                                                                  \n",
            " conv_101 (Conv2D)              (None, 52, 52, 128)  32768       ['leake_100[0][0]']              \n",
            "                                                                                                  \n",
            " bnorm_101 (BatchNormalization)  (None, 52, 52, 128)  512        ['conv_101[0][0]']               \n",
            "                                                                                                  \n",
            " leake_101 (LeakyReLU)          (None, 52, 52, 128)  0           ['bnorm_101[0][0]']              \n",
            "                                                                                                  \n",
            " conv_102 (Conv2D)              (None, 52, 52, 256)  294912      ['leake_101[0][0]']              \n",
            "                                                                                                  \n",
            " bnorm_102 (BatchNormalization)  (None, 52, 52, 256)  1024       ['conv_102[0][0]']               \n",
            "                                                                                                  \n",
            " leake_102 (LeakyReLU)          (None, 52, 52, 256)  0           ['bnorm_102[0][0]']              \n",
            "                                                                                                  \n",
            " conv_103 (Conv2D)              (None, 52, 52, 128)  32768       ['leake_102[0][0]']              \n",
            "                                                                                                  \n",
            " bnorm_103 (BatchNormalization)  (None, 52, 52, 128)  512        ['conv_103[0][0]']               \n",
            "                                                                                                  \n",
            " leake_103 (LeakyReLU)          (None, 52, 52, 128)  0           ['bnorm_103[0][0]']              \n",
            "                                                                                                  \n",
            " conv_80 (Conv2D)               (None, 13, 13, 1024  4718592     ['leake_79[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_92 (Conv2D)               (None, 26, 26, 512)  1179648     ['leake_91[0][0]']               \n",
            "                                                                                                  \n",
            " conv_104 (Conv2D)              (None, 52, 52, 256)  294912      ['leake_103[0][0]']              \n",
            "                                                                                                  \n",
            " bnorm_80 (BatchNormalization)  (None, 13, 13, 1024  4096        ['conv_80[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bnorm_92 (BatchNormalization)  (None, 26, 26, 512)  2048        ['conv_92[0][0]']                \n",
            "                                                                                                  \n",
            " bnorm_104 (BatchNormalization)  (None, 52, 52, 256)  1024       ['conv_104[0][0]']               \n",
            "                                                                                                  \n",
            " leake_80 (LeakyReLU)           (None, 13, 13, 1024  0           ['bnorm_80[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leake_92 (LeakyReLU)           (None, 26, 26, 512)  0           ['bnorm_92[0][0]']               \n",
            "                                                                                                  \n",
            " leake_104 (LeakyReLU)          (None, 52, 52, 256)  0           ['bnorm_104[0][0]']              \n",
            "                                                                                                  \n",
            " conv_81 (Conv2D)               (None, 13, 13, 18)   18450       ['leake_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv_93 (Conv2D)               (None, 26, 26, 18)   9234        ['leake_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv_105 (Conv2D)              (None, 52, 52, 18)   4626        ['leake_104[0][0]']              \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 13, 13, 3,   0           []                               \n",
            "                                6)]                                                               \n",
            "                                                                                                  \n",
            " input_12 (InputLayer)          [(None, 26, 26, 3,   0           []                               \n",
            "                                6)]                                                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None, 52, 52, 3,   0           []                               \n",
            "                                6)]                                                               \n",
            "                                                                                                  \n",
            " yolo_loss (Lambda)             ()                   0           ['conv_81[0][0]',                \n",
            "                                                                  'conv_93[0][0]',                \n",
            "                                                                  'conv_105[0][0]',               \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]',               \n",
            "                                                                  'input_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 61,576,342\n",
            "Trainable params: 61,523,734\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELsxOJNO0eDF"
      },
      "source": [
        "# Компилируем модель\n",
        "optimizer = Adam(learning_rate=1e-3)\n",
        "model_YOLO.compile(optimizer=optimizer, loss={'yolo_loss': lambda y_true, y_pred: y_pred})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o57ehSi4u4y9"
      },
      "source": [
        "# Задаем Колбэки\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          mode = 'min', \n",
        "                          min_delta = 0,\n",
        "                          patience = 7,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "model_Checkpoint = ModelCheckpoint(filepath = weights_path, \n",
        "                                   monitor = 'val_loss', \n",
        "                                   verbose = 1, \n",
        "                                   save_best_only = True,\n",
        "                                   mode = 'min', \n",
        "                                   baseline = 0.5)\n",
        "\n",
        "reduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', \n",
        "                                      factor=0.7, \n",
        "                                      patience=3, \n",
        "                                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачиваем датасет с изображениями для тестирования модели\n",
        "import gdown\n",
        "\n",
        "gdown.download('https://storage.googleapis.com/datasets_ai/Advanced/9_OD/Airplane.zip', None, quiet=True)\n",
        "\n",
        "# Распаковываем датасет\n",
        "!unzip -q Airplane.zip"
      ],
      "metadata": {
        "id": "nUUsHZNfYGAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE8OL7svafgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25339018-14be-4dc6-d61d-11c574dff06e"
      },
      "source": [
        "All_data = np.load(gdown.download('https://storage.googleapis.com/datasets_ai/Advanced/9_OD/aircraft_np_base.npy', None, quiet=True))\n",
        "\n",
        "val_split = 0.1 # Коэфициент разделения на обучающую и проверочную выборку\n",
        "\n",
        "# Перемешаем значения в массиве\n",
        "np.random.seed(17)\n",
        "np.random.shuffle(All_data)\n",
        "np.random.seed(None)\n",
        "\n",
        "num_val = int(len(All_data) * val_split) # Количество элементов проверочной выборки\n",
        "num_train = len(All_data) - num_val # Количество элементов обучающей выборки\n",
        "print(num_val)\n",
        "print(num_train)\n",
        "print(All_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "900\n",
            "(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запускаем процесс обучения на 100 эпохах\n",
        "batch_size = 32\n",
        "\n",
        "history = model_YOLO.fit(data_generator(All_data[:num_train], \n",
        "                                        batch_size, \n",
        "                                        anchors, \n",
        "                                        inputs),\n",
        "                        steps_per_epoch = max (1, num_train//batch_size),\n",
        "                        validation_data = data_generator(All_data[num_train:], \n",
        "                                                         batch_size, \n",
        "                                                         anchors, \n",
        "                                                         inputs),\n",
        "                        validation_steps = max (1, num_val//batch_size), \n",
        "                        epochs = 2, \n",
        "                        verbose = 1, \n",
        "                        initial_epoch = 0, \n",
        "                        callbacks=[model_Checkpoint, \n",
        "                                   reduceLROnPlateau])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "wuTqsFKUQkYM",
        "outputId": "2b2f4335-327a-40e6-967d-2198ca5829eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-bdc8e1a60400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                         callbacks=[model_Checkpoint, \n\u001b[0;32m---> 18\u001b[0;31m                                    reduceLROnPlateau])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-da72b8751a5c>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(annotation_lines, batch_size, anchors, input_shape)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# По значению ограничивающей рамки получаем y_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-585c12f312cc>\u001b[0m in \u001b[0;36mget_y\u001b[0;34m(true_boxes, anchors, input_shape)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Преобразуем input_shape в numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Получаем координаты центра bounding_box (xRight+xLeft / 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 416, 416, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation(All_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W6doiPXYhLr",
        "outputId": "f37e07c7-8457-447b-ebd8-2dfa8df5713c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         ...,\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388]],\n",
              " \n",
              "        [[0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         ...,\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388]],\n",
              " \n",
              "        [[0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         ...,\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388]],\n",
              " \n",
              "        [[0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         ...,\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388]],\n",
              " \n",
              "        [[0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         ...,\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388],\n",
              "         [0.50052388, 0.50052388, 0.50052388]]]),\n",
              " array([[  1.,  72., 416., 282.,   0.],\n",
              "        [  0.,   0.,   0.,   0.,   0.],\n",
              "        [  0.,   0.,   0.,   0.,   0.],\n",
              "        [  0.,   0.,   0.,   0.,   0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/dataset2/airplanes/Airplane/airplane_194.jpg\n",
        "/content/dataset2/airplanes/Airplane/airplane_194.jpg"
      ],
      "metadata": {
        "id": "3ML46Ipqum2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rm2ndMiy5RU"
      },
      "source": [
        "# Запускаем процесс обучения на 100 эпохах\n",
        "\n",
        "history = model_YOLO.fit(data_generator(All_data[:num_train], batch_size, anchors, input_shape),\n",
        "                        steps_per_epoch = max (1, num_train//batch_size),\n",
        "                        validation_data = data_generator(All_data[num_train:], batch_size, anchors, input_shape),\n",
        "                        validation_steps = max (1, num_val//batch_size), epochs = 100, verbose = 1, initial_epoch = 0, \n",
        "                        callbacks=[model_Checkpoint, reduceLROnPlateau])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D39gFt8ihpA3"
      },
      "source": [
        "## Тестируем обученную модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTzoORJqHSmS"
      },
      "source": [
        "## Функция для обнаружения объект"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcipJhT_1Awg"
      },
      "source": [
        "def object_detection_2 (filename, model_YOLO, probability=0.7, x_size=12, y_size=17):\n",
        "    \n",
        "    name_classes = ['Самолеты']\n",
        "    num_classes = len(name_classes)\n",
        "    anchors = np.array([[10,13], [16,30], [33,23], [30, 61], [62,45], [59,119], [116, 90], [156, 198], [373, 326]])\n",
        "    \n",
        "    image = Image.open(filename) # Загружаем изображение\n",
        "    \n",
        "    # Создаем набор цветов для ограничивающих рамок\n",
        "    import colorsys \n",
        "    hsv_tuples = [(x / len(name_classes), 1., 1.) for x in range(len(name_classes))]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x:(int(x[0]*255), int(x[1]*255), int(x[2]*255)), colors))\n",
        "    np.random.seed(43)\n",
        "    np.random.shuffle(colors)\n",
        "    np.random.seed(None)\n",
        "\n",
        "    # Изменяем размер картинки под input_shape\n",
        "    iw, ih = image.size\n",
        "    w, h = (416, 416)\n",
        "    scale = min(w / iw, h / ih)\n",
        "    nw = int(iw * scale)\n",
        "    nh = int(ih * scale)\n",
        "    image_for_predict = image.resize((nw, nh), Image.BICUBIC)\n",
        "    new_image = Image.new('RGB', (416,416), (128, 128, 128))\n",
        "    new_image.paste(image_for_predict, ((w - nw) // 2, (h - nh) // 2))\n",
        "    image_for_predict = new_image \n",
        "    image_for_predict = np.array(image_for_predict) / 255.\n",
        "    image_for_predict = image_for_predict.reshape(1, 416, 416, 3)\n",
        "\n",
        "    predict = model_YOLO.predict(image_for_predict)\n",
        "    num_layers = len(predict) # Получаем количество сеток\n",
        "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] # Задаем маски для 3 уровней анкоров\n",
        "    input_shape = np.array(predict[0].shape[1:3]) * 32  # Получаем размер выходного изображения\n",
        "    image_shape = np.array([image.size[1], image.size[0]]) # Сохраняем размер оригинального изображения\n",
        "\n",
        "    level_anchor = 0 # Укажем уровень сетки\n",
        "    num_anchors = len(anchors[anchor_mask[level_anchor]]) # Получаем количество анкоров\n",
        "    anchors_tensor = np.reshape(anchors[anchor_mask[level_anchor]], (1,1,1,num_anchors,2)) # Выбираем анкоры для нашего уровня сетки и решейпим\n",
        "\n",
        "    # Создаем пустую сетку\n",
        "    grid_shape = predict[level_anchor].shape[1:3] # Получим размерность сетки\n",
        "    grid = [] # Массив для финальной сетки\n",
        "    grid_row = [] # Массив для столбца\n",
        "    for i in range(grid_shape[0]): # По всем строкам\n",
        "      for j in range(grid_shape[1]): # По всем столбцам\n",
        "        grid_row.append([j , i]) # Создаем элемент [j, i]\n",
        "      grid.append(grid_row) # Добавляем столбец в финальную сетку\n",
        "      grid_row = [] # Обнуляем данные для столбца\n",
        "    grid = np.array(grid) # Переводим в numpy\n",
        "    grid = np.expand_dims(grid, axis=2) # Добавляем размерность\n",
        "\n",
        "    # Функция расчета сигмоиды для вектора\n",
        "    def sigmoid(x): # На вход подаем массив данных\n",
        "      return 1/(1+np.exp(-x)) # Возвращаем сигмоиду для всех элементов массива\n",
        "\n",
        "    # Решейпим предикт\n",
        "    feats = np.reshape(predict[level_anchor], (-1, grid_shape[0], grid_shape[1], num_anchors, num_classes+5))\n",
        "\n",
        "    # Координаты центра bounding box\n",
        "    xy_param = feats[..., :2] # Выцепляем 0 и 1 параметры из предикта (соответствуют параметрам смещения центра анкора)\n",
        "    box_xy = (sigmoid(xy_param) + grid)/grid_shape[::-1] # Получаем координаты центра bounding box\n",
        "\n",
        "    # Высота и ширна bounding box\n",
        "    wh_param = feats[..., 2:4] # Выцепляем 2 и 3 параметры из предикта (соответствуют праметрам изменения высоты и ширины анкора)\n",
        "    box_wh = np.exp(wh_param) * anchors_tensor / input_shape[::-1] # Получаем высоту и ширину bounding box\n",
        "\n",
        "    # Вероятность наличия объекта в анкоре\n",
        "    conf_param = feats[..., 4:5] # Выцепляем 4 параметр из предикта (соответствуют вероятности обнаружения объекта)\n",
        "    box_confidence = sigmoid(conf_param) # Получаем вероятность наличия объекта в bounding box\n",
        "\n",
        "    # Класс объекта\n",
        "    class_param = feats[...,5:] # Выцепляем 5+ параметры из предикта (соответствуют вероятностям классов объектов)\n",
        "    box_class_probs = sigmoid(class_param) # Получаем вероятности классов объектов\n",
        "\n",
        "    # Корректируем ограничивающие рамки (Размер изображения на выходе 416х416)\n",
        "    # И найденные параметры соответствуют именно этой размерности\n",
        "    # Необходимо найти координаты bounding box для рамерности исходного изображения\n",
        "    box_yx = box_xy[..., ::-1].copy()\n",
        "    box_hw = box_wh[..., ::-1].copy()\n",
        "\n",
        "    new_shape = np.round(image_shape * np.min(input_shape/image_shape)) # Находим размерность пропорциональную исходной с одной из сторон 416\n",
        "    offset = (input_shape-new_shape)/2./input_shape # Смотрим на сколько надо сместить в относительных координатах\n",
        "    scale = input_shape/new_shape  # Находим коэфициент масштабирования\n",
        "    box_yx = (box_yx - offset) * scale # Смещаем по координатам\n",
        "    box_hw *= scale # Масштабируем ширину и высоту\n",
        "\n",
        "    box_mins = box_yx - (box_hw / 2.) # Получаем левые верхние координаты (от середины отнимаем половину ширины и высоты)\n",
        "    box_maxes = box_yx + (box_hw / 2.) # Получаем правые нижнние координаты (к середине прибавляем половину ширины и высоты)\n",
        "    \n",
        "    _boxes =  np.concatenate([\n",
        "    box_mins[..., 0:1], # yMin\n",
        "    box_mins[..., 1:2], # xMin\n",
        "    box_maxes[..., 0:1], # yMax\n",
        "    box_maxes[..., 1:2]  # xMax\n",
        "    ], axis=-1)\n",
        "\n",
        "    _boxes *= np.concatenate([image_shape, image_shape]) # Переводим из относительных координат в абсолютные\n",
        "\n",
        "    # Получаем выходные параметры\n",
        "    _boxes_reshape = np.reshape(_boxes, (-1, 4)) # Решейпим все боксы в один массив\n",
        "    _box_scores = box_confidence * box_class_probs # Получаем вероятность каждого класса (умноженную на веоятность наличия объекта)\n",
        "    _box_scores_reshape = np.reshape(_box_scores, (-1, num_classes)) # Решейпим в один массив\n",
        "\n",
        "    mask = _box_scores_reshape >= probability # Берем все объекты, обнаруженные с вероятностью больше 0.7\n",
        "    _boxes_out = _boxes_reshape[mask[:,0]]\n",
        "    _scores_out = _box_scores_reshape[:, 0][mask[:,0]] \n",
        "    classes_out = np.ones_like(_scores_out,'int32') * 0\n",
        "    font = ImageFont.truetype(font=path + 'font.otf', size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
        "    thickness = (image.size[0] + image.size[1]) // 300\n",
        "\n",
        "    image_pred = image.copy()\n",
        "    for i, c in reversed(list(enumerate(classes_out))):\n",
        "      #print(c)\n",
        "      draw = ImageDraw.Draw(image_pred)\n",
        "      predicted_class = name_classes[c]\n",
        "      box = _boxes_out[i]\n",
        "      score = _scores_out[i]\n",
        "\n",
        "      label = '{} {:.2f}'.format(predicted_class, score)\n",
        "      label_size = draw.textsize(label, font)\n",
        "\n",
        "      top, left, bottom, right = box\n",
        "      top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "      left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "      bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
        "      right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
        "      #print(label, (left, top), (right, bottom))\n",
        "\n",
        "      if top - label_size[1] >= 0:\n",
        "          text_origin = np.array([left, top - label_size[1]])\n",
        "      else:\n",
        "          text_origin = np.array([left, top + 1])\n",
        "  \n",
        "      for i in range(thickness):\n",
        "          draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
        "      draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
        "      draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "      del draw\n",
        "    image_pred.save('new_image.jpg')\n",
        "    plt.figure(figsize=(x_size,y_size))\n",
        "    plt.imshow(image_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPqjkQOlHiAW"
      },
      "source": [
        "## Тестирование модели на собственных весах"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqn4o-H8H5wt"
      },
      "source": [
        "Создаем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5okqowGd1xsb"
      },
      "source": [
        "yolo3 = create_yolov3_model(Input(shape=(416, 416, 3)), 3, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Wg4VB9H8AL"
      },
      "source": [
        "Загружаем полученные во время обучения веса со своего гугл диска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FaFcNg219UP"
      },
      "source": [
        "yolo3.load_weights(weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfYzciaSGwe0"
      },
      "source": [
        "или из облака "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m3yjtYcGjNS"
      },
      "source": [
        "yolo3.load_weights(gdown.download('https://storage.googleapis.com/datasets_ai/Advanced/9_OD/yolo_new.h5', None, quiet=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brZo5lOpIM4O"
      },
      "source": [
        "указываем папку с фотографиями"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачиваем датасет с изображениями для тестирования модели\n",
        "import gdown\n",
        "\n",
        "gdown.download('https://storage.googleapis.com/datasets_ai/Advanced/9_OD/airplanes.zip', None, quiet=True)\n",
        "\n",
        "# Распаковываем датасет\n",
        "!unzip -q airplanes.zip -d dataset2\n",
        "\n",
        "source_dir2 = 'dataset2/airplane'"
      ],
      "metadata": {
        "id": "TI3aydsMMw4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgFP1yXMIECU"
      },
      "source": [
        "# Получаем список путей ко всем файлам с их именами\n",
        "\n",
        "file_list = get_file_paths(source_dir2+'/**'+ '/*.jpg')\n",
        "print(len(file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvIj-U8tK8uY"
      },
      "source": [
        "object_detection(yolo3, file_list[:3],0.5, labels=['Самолёт'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shHNGxWM6ixw"
      },
      "source": [
        "for i in range(5):\n",
        "  object_detection_2(file_list[random.randint(0,len(file_list))],yolo3, 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgX-ykMO8S_d"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/15jlTRqgJCqFbyw_bSg9UTB1cBjH5SYt_?usp=sharing)\n",
        "2. [Практический ноутбук 1](https://colab.research.google.com/drive/1qNMeH5RPNG3kJQrH5FbyfsJUCzA3xPRO?usp=sharing)\n",
        "3. [Практический ноутбук 2](https://colab.research.google.com/drive/1638S62UBT1_uaBXcE7qT1AoagPRB_zJP?usp=sharing)\n",
        "4. Практический ноутбук 3\n"
      ]
    }
  ]
}